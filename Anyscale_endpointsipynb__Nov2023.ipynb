{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzvRuJJSHpo1"
   },
   "outputs": [],
   "source": [
    "#%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opentelemetry-util-http==0.42b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting anyio<4,>=3.5.0 (from openai)\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.25.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.5 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.2.0-py3-none-any.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.9/219.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, pydantic-core, h11, distro, anyio, annotated-types, pydantic, httpcore, httpx, openai\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "Successfully installed annotated-types-0.6.0 anyio-3.7.1 distro-1.8.0 h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 openai-1.2.0 pydantic-2.4.2 pydantic-core-2.10.1 tqdm-4.66.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xmJpvFhHGgot"
   },
   "outputs": [],
   "source": [
    "#%pip install langflow==0.5.7\n",
    "#!python -m langflow\n",
    "#%pip install 'openai<0.28.0,>=0.27.8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JshLsEYK9I1"
   },
   "source": [
    "## Testing The OpenAI call with Anyscale Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x-97Io4RnffZ"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ShakeSwift\n",
      "2. HealthMix\n",
      "3. CompactMilkshaker\n",
      "4. FitBlend\n",
      "5. QuickMix\n",
      "6. ShakeMate\n",
      "7. SlimShake\n",
      "8. MilkshakeExpress\n",
      "9. NutriShake\n",
      "10. SwiftBlend.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "#from openai.types import chat\n",
    "#import openai\n",
    "#openai.api_key = \"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\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "\n",
    "system_content = \"You will be provided with a product description and seed words. Your task is to generate potential product names.\"\n",
    "user_content = \"Product description: A home milkshake maker. Seed words: fast, healthy, compact.\"\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature=0.7\n",
    ")\n",
    "#product_names = chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "#print(\"Results from the OpenAI endpoint:\\n\", product_names)\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XYF708dMpGLE"
   },
   "outputs": [],
   "source": [
    "#It should return an error due to changes and openai Update recently , if it didn't then it's fixed\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "#https://huggingface.co/meta-llama  -- here is where i can find the actual models names\n",
    "#chat_completion = client.chat.completions.create(\n",
    "#    #api_base = \"https://api.endpoints.anyscale.com/v1\",   TypeError: Completions.create() got an unexpected keyword argument 'api_base'\n",
    "#    #api_key=\"esecret_hanjm9lbkdr62f7csy3fem5fvy\",      TypeError: Completions.create() got an unexpected keyword argument 'api_key'  \n",
    "#    model=\"Llama-2-70b-chat-hf\",                         #The model `meta-llama/Llama-2-70b-chat-hf` does not exist\n",
    "#    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "#              {\"role\": \"user\", \"content\": user_content}],\n",
    "#    temperature=0.7\n",
    "#)\n",
    "\n",
    "#product_names = chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "#print(\"Results from Anyscale Endpoint:\\n\", product_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU-5cmrqLz9v"
   },
   "source": [
    "# Anyscale Endpoints direct Query\n",
    "This is the direct connection to access Open source LLM like LLama2-70b, llama2-13b etc If using Premium version of anyscale you could finetune models and use custom models. you can define a function to avoid rewriting the code just tweak with some indentation using *def* keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oExOVYptxslR"
   },
   "outputs": [],
   "source": [
    "query = 'who are you?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rQBdpioXxCuT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot Response:\n",
      "  Greetings! I am Kamal, a helpful doctor. I am here to assist you with any medical-related questions or concerns you may have. How can I be of assistance to you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "#api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "#token = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = \"https://api.endpoints.anyscale.com/v1\"\n",
    "token = \"esecret_4fvbprd1pf4t1fziay6fpz1elg\"\n",
    "url = f\"{api_base}/chat/completions\"\n",
    "body = {\n",
    "  \"model\": \"meta-llama/Llama-2-70b-chat-hf\",\n",
    "  \"messages\": [{\"role\": \"system\", \"content\": \"Your name is Kamal and you are a helpful doctor.\"}, {\"role\": \"user\", \"content\": query}],\n",
    "  \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "response = s.post(url, headers={\"Authorization\": f\"Bearer {token}\"}, json=body)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_json = response.json()\n",
    "    chatbot_response = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"Chatbot Response:\")\n",
    "    print(chatbot_response)\n",
    "else:\n",
    "    print(f\"Request failed with status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
