{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzvRuJJSHpo1"
   },
   "outputs": [],
   "source": [
    "#%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opentelemetry-util-http==0.42b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting anyio<4,>=3.5.0 (from openai)\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.25.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.5 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.2.0-py3-none-any.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.9/219.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, pydantic-core, h11, distro, anyio, annotated-types, pydantic, httpcore, httpx, openai\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "Successfully installed annotated-types-0.6.0 anyio-3.7.1 distro-1.8.0 h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 openai-1.2.0 pydantic-2.4.2 pydantic-core-2.10.1 tqdm-4.66.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xmJpvFhHGgot"
   },
   "outputs": [],
   "source": [
    "#%pip install langflow==0.5.7\n",
    "#!python -m langflow\n",
    "#%pip install 'openai<0.28.0,>=0.27.8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JshLsEYK9I1"
   },
   "source": [
    "## Testing The OpenAI call with Anyscale Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x-97Io4RnffZ"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ShakeSwift\n",
      "2. HealthMix\n",
      "3. CompactMilkshaker\n",
      "4. FitBlend\n",
      "5. QuickMix\n",
      "6. ShakeMate\n",
      "7. SlimShake\n",
      "8. MilkshakeExpress\n",
      "9. NutriShake\n",
      "10. SwiftBlend.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "#from openai.types import chat\n",
    "#import openai\n",
    "#openai.api_key = \"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\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "\n",
    "system_content = \"You will be provided with a product description and seed words. Your task is to generate potential product names.\"\n",
    "user_content = \"Product description: A home milkshake maker. Seed words: fast, healthy, compact.\"\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature=0.7\n",
    ")\n",
    "#product_names = chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "#print(\"Results from the OpenAI endpoint:\\n\", product_names)\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XYF708dMpGLE"
   },
   "outputs": [],
   "source": [
    "#It should return an error due to changes and openai Update recently , if it didn't then it's fixed\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "#https://huggingface.co/meta-llama  -- here is where i can find the actual models names\n",
    "#chat_completion = client.chat.completions.create(\n",
    "#    #api_base = \"https://api.endpoints.anyscale.com/v1\",   TypeError: Completions.create() got an unexpected keyword argument 'api_base'\n",
    "#    #api_key=\"esecret_hanjm9lbkdr62f7csy3fem5fvy\",      TypeError: Completions.create() got an unexpected keyword argument 'api_key'  \n",
    "#    model=\"Llama-2-70b-chat-hf\",                         #The model `meta-llama/Llama-2-70b-chat-hf` does not exist\n",
    "#    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "#              {\"role\": \"user\", \"content\": user_content}],\n",
    "#    temperature=0.7\n",
    "#)\n",
    "\n",
    "#product_names = chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "#print(\"Results from Anyscale Endpoint:\\n\", product_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU-5cmrqLz9v"
   },
   "source": [
    "# Anyscale Endpoints direct Query\n",
    "This is the direct connection to access Open source LLM like LLama2-70b, llama2-13b etc If using Premium version of anyscale you could finetune models and use custom models. you can define a function to avoid rewriting the code just tweak with some indentation using *def* keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oExOVYptxslR"
   },
   "outputs": [],
   "source": [
    "query = 'who are you?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rQBdpioXxCuT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot Response:\n",
      "  Greetings! I am Kamal, a helpful doctor. I am here to assist you with any medical-related questions or concerns you may have. How can I be of assistance to you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "#api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "#token = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = \"https://api.endpoints.anyscale.com/v1\"\n",
    "token = \"esecret_4fvbprd1pf4t1fziay6fpz1elg\"\n",
    "url = f\"{api_base}/chat/completions\"\n",
    "body = {\n",
    "  \"model\": \"meta-llama/Llama-2-70b-chat-hf\",\n",
    "  \"messages\": [{\"role\": \"system\", \"content\": \"Your name is Kamal and you are a helpful doctor.\"}, {\"role\": \"user\", \"content\": query}],\n",
    "  \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "response = s.post(url, headers={\"Authorization\": f\"Bearer {token}\"}, json=body)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_json = response.json()\n",
    "    chatbot_response = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"Chatbot Response:\")\n",
    "    print(chatbot_response)\n",
    "else:\n",
    "    print(f\"Request failed with status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.332-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: anyio<4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.52 (from langchain)\n",
      "  Downloading langsmith-0.0.62-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Collecting pytest-subtests<0.12.0,>=0.11.0 (from langsmith<0.1.0,>=0.0.52->langchain)\n",
      "  Downloading pytest_subtests-0.11.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/codespace/.local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
      "Collecting pytest>=7.0 (from pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain)\n",
      "  Downloading pytest-7.4.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting iniconfig (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting pluggy<2.0,>=0.12 (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain)\n",
      "  Downloading pluggy-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain) (2.0.1)\n",
      "Downloading langchain-0.0.332-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.0.62-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.2/613.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytest_subtests-0.11.0-py3-none-any.whl (6.7 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading pytest-7.4.3-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.1/325.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pluggy-1.3.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: pluggy, mypy-extensions, multidict, marshmallow, jsonpatch, iniconfig, greenlet, frozenlist, async-timeout, yarl, typing-inspect, SQLAlchemy, pytest, aiosignal, pytest-subtests, dataclasses-json, aiohttp, langsmith, langchain\n",
      "Successfully installed SQLAlchemy-2.0.23 aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.1 frozenlist-1.4.0 greenlet-3.0.1 iniconfig-2.0.0 jsonpatch-1.33 langchain-0.0.332 langsmith-0.0.62 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 pluggy-1.3.0 pytest-7.4.3 pytest-subtests-0.11.0 typing-inspect-0.9.0 yarl-1.9.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Vectara\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI \n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "OPENAI_API_KEY = \"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\" #os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a text file 'sample.txt' that you want to load\n",
    "file_path = 'state_of_the_union.txt'\n",
    "\n",
    "# Create an instance of TextLoader\n",
    "text_loader = TextLoader(file_path)\n",
    "\n",
    "# Use the load method to read the text from the file\n",
    "documents = text_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv('OPENAI_API_KEY'))\n",
    "print(os.getenv('VECTARA_CUSTOMER_ID'))\n",
    "print(os.getenv('VECTARA_CORPUS_ID'))\n",
    "print(os.getenv('VECTARA_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't find Vectara credentials, customer_id or corpus_id in environment.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "VECTARA_CUSTOMER_ID = os.getenv('VECTARA_CUSTOMER_ID')\n",
    "VECTARA_CORPUS_ID = os.getenv('VECTARA_CORPUS_ID')\n",
    "VECTARA_API_KEY = os.getenv('VECTARA_API_KEY')\n",
    "\n",
    "# Load data (docs) into vectara DB\n",
    "vectara  = Vectara.from_documents(documents, embedding=None)\n",
    "\n",
    "#qa = RetrievalQA.from_llm(llm=OpenAI(), retriever = vectara.as_retriever())\n",
    "\n",
    "#question = 'According to the document, what did Vladimir Putin miscalculate?'\n",
    "\n",
    "#answer = qa({\"query\": question})\n",
    "\n",
    "#print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('state_of_the_union.txt')\n",
    "#documents = loader.load()\n",
    "#vectara  = Vectara.from_documents(documents)\n",
    "\n",
    "#qa = RetrievalQA.from_llm(llm=OpenAI(), retriever=vectara.as_retriever())\n",
    "\n",
    "#print(qa({“query”:  “According to the document, what did Vladimir Putin miscalculate?”}))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
